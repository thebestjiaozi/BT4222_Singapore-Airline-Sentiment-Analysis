{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wX1XLdMxn8sm"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check cuda status\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "metadata": {
        "id": "LCLpu_PqoGFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9e08b3-41a6-46b5-bde5-ca2e94a5e6bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available, CPU used\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Project_data/train_split.csv\")\n",
        "val_df = pd.read_csv(\"/content/drive/MyDrive/Project_data/val_split.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Project_data/test_split.csv\")"
      ],
      "metadata": {
        "id": "-P04WpsMoGzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300136a4-4d11-4dcf-ebef-6653b1825d90"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'shape of train data is {train_df.shape}')\n",
        "print(f'shape of test data is {val_df.shape}')\n",
        "print(f'shape of test data is {test_df.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlOh8NjZ4b_R",
        "outputId": "5f234d7a-7da8-43e4-ae78-aa033133ae0d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train data is (7000, 3)\n",
            "shape of test data is (1000, 3)\n",
            "shape of test data is (2000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "# Tokenization\n",
        "def preprocess_string(s):\n",
        "    # Remove all non-word characters (everything except numbers and letters)\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    # Replace all runs of whitespaces with no space\n",
        "    s = re.sub(r\"\\s+\", '', s)\n",
        "    # replace digits with no space\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "\n",
        "    return s.strip().lower()\n",
        "\n",
        "def tokenize_text(train_df, val_df, test_df, vocab_size=1000):\n",
        "    word_list = []\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    for text in train_df['text']:\n",
        "        for word in text.split():\n",
        "            word = preprocess_string(word)\n",
        "            if word and word not in stop_words:\n",
        "                word_list.append(word)\n",
        "\n",
        "    corpus = Counter(word_list)\n",
        "    top_words = sorted(corpus, key=corpus.get, reverse=True)[:vocab_size]\n",
        "    onehot_dict = {w: i+1 for i, w in enumerate(top_words)}\n",
        "\n",
        "    def tokenize_column(df):\n",
        "        tokenized = []\n",
        "        for text in df['text']:\n",
        "            tokens = [onehot_dict[preprocess_string(word)]\n",
        "                      for word in text.split()\n",
        "                      if preprocess_string(word) in onehot_dict]\n",
        "            tokenized.append(tokens)\n",
        "        return np.array(tokenized, dtype=object)\n",
        "\n",
        "\n",
        "    x_train_tokens = tokenize_column(train_df)\n",
        "    x_val_tokens   = tokenize_column(val_df)\n",
        "    x_test_tokens  = tokenize_column(test_df)\n",
        "\n",
        "    y_train = train_df['label'].values\n",
        "    y_val   = val_df['label'].values\n",
        "    y_test  = test_df['label'].values\n",
        "\n",
        "    return x_train_tokens, y_train, x_val_tokens, y_val, x_test_tokens, y_test, onehot_dict\n",
        "\n",
        "x_train, y_train, x_val, y_val, x_test, y_test, vocab = tokenize_text(train_df, val_df, test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYlFntyr4pha",
        "outputId": "4c06f9e9-5441-476f-ad16-d82cb208ea58"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Length of vocabulary is {len(vocab)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCuN_arzBTmZ",
        "outputId": "6d32506d-2a8e-4ac8-ebea-fc4beb58069f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of vocabulary is 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rev_len = [len(i) for i in x_train]\n",
        "pd.Series(rev_len).hist()\n",
        "plt.show()\n",
        "pd.Series(rev_len).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "YAKjJceZB5Dh",
        "outputId": "c528d74b-0848-4849-d8d5-7ab69dc935fe"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    7000.000000\n",
              "mean       41.810714\n",
              "std        41.401312\n",
              "min         4.000000\n",
              "25%        20.000000\n",
              "50%        31.000000\n",
              "75%        50.000000\n",
              "max      1123.000000\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>41.810714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>41.401312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1123.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "count = 7000 -> There are 7000 training samples. <br>\n",
        "mean = 41.8 -> On average, each review has around 42 tokens. <br>\n",
        "std = 41.4 -> There’s large standard deviation. Some reviews are very short while some are very long. <br>\n",
        "min = 4\t-> The shortest review has only 4 tokens. <br>\n",
        "25% = 20 -> 25% of reviews have ≤ 20 tokens. <br>\n",
        "50% = 31 -> Half of the reviews have ≤ 31 tokens. <br>\n",
        "75% = 50 -> 75% of reviews have ≤ 50 tokens. <br>\n",
        "max = 1123 -> The longest review is 1123 tokens long"
      ],
      "metadata": {
        "id": "ICGkPbmWCovG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n Text input: {}\\n'.format(x_train[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Q2eLoFDSv7",
        "outputId": "9a51d03d-5afd-4aa1-ff8e-6742f29ae497"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Text input: [22, 25, 161, 18, 11, 364, 22, 3, 30, 2, 76, 77, 82, 61, 147]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in [90, 95, 99]:\n",
        "    print(f\"{p}th percentile length: {np.percentile(rev_len, p):.0f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1KuHUEGD-RW",
        "outputId": "814770e8-8349-4795-820d-b68008675279"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90th percentile length: 77\n",
            "95th percentile length: 106\n",
            "99th percentile length: 192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "    return features\n",
        "\n",
        "#we have very less number of reviews with length > 120 as the 95th percentile length is 106.\n",
        "#So we will consider only those below it.\n",
        "x_train_pad = padding_(x_train, 120)\n",
        "x_val_pad   = padding_(x_val, 120)\n",
        "x_test_pad  = padding_(x_test, 120)"
      ],
      "metadata": {
        "id": "UpL_UhkIDo9y"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_val   = le.transform(y_val)\n",
        "y_test  = le.transform(y_test)\n",
        "\n",
        "print(le.classes_)  #should print ['negative' 'neutral' 'positive']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD_y43Eb86yI",
        "outputId": "5c8604ff-e101-4ae7-9ab2-16de4d895ff5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['negative' 'neutral' 'positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(\n",
        "    torch.from_numpy(x_train_pad),\n",
        "    torch.from_numpy(y_train)\n",
        ")\n",
        "\n",
        "val_data = TensorDataset(\n",
        "    torch.from_numpy(x_val_pad),\n",
        "    torch.from_numpy(y_val)\n",
        ")\n",
        "\n",
        "test_data = TensorDataset(\n",
        "    torch.from_numpy(x_test_pad),\n",
        "    torch.from_numpy(y_test)\n",
        ")\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "val_loader   = DataLoader(val_data,   shuffle=True, batch_size=batch_size)\n",
        "test_loader  = DataLoader(test_data,  shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "N318VTz478G7"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample sentences x: \\n', sample_x)\n",
        "print('Sample targets y: \\n', sample_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnaWPXSJ-GCB",
        "outputId": "df7ba954-e12c-429d-d705-6b910b946652"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([50, 120])\n",
            "Sample sentences x: \n",
            " tensor([[  0,   0,   0,  ...,  29, 532, 104],\n",
            "        [  0,   0,   0,  ...,  49, 442,  89],\n",
            "        [  0,   0,   0,  ..., 460, 331, 252],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ..., 261, 106,   4],\n",
            "        [  0,   0,   0,  ..., 976,  47,   4],\n",
            "        [  0,   0,   0,  ..., 222, 132, 718]])\n",
            "Sample targets y: \n",
            " tensor([2, 2, 0, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2, 1, 0, 2, 2, 2, 2, 2, 1,\n",
            "        0, 0, 2, 1, 2, 2, 2, 1, 0, 2, 2, 2, 1, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 0,\n",
            "        2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        embedding_dim=128,\n",
        "        hidden_dim=128,\n",
        "        num_layers=2,\n",
        "        num_classes=3,         #3 classes from le()\n",
        "        bidirectional=True,\n",
        "        dropout=0.3,\n",
        "        pad_idx=0               #padding index is 0\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * self.num_directions, num_classes)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        emb = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(emb, hidden)\n",
        "        last_hidden = lstm_out[:, -1, :]\n",
        "        out = self.dropout(last_hidden)\n",
        "        logits = self.fc(out)          # [B, 3]\n",
        "        return logits, hidden          # CE expects raw logits + int targets\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size, device):\n",
        "        h0 = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_dim, device=device)\n",
        "        c0 = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_dim, device=device)\n",
        "        return (h0, c0)"
      ],
      "metadata": {
        "id": "D6sG1jpj_CRR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab) + 1      # +1 for PAD=0\n",
        "model = SentimentRNN(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=96,\n",
        "    hidden_dim=96,\n",
        "    num_layers=2,\n",
        "    num_classes=3,\n",
        "    bidirectional=True,\n",
        "    dropout=0.3,\n",
        "    pad_idx=0\n",
        ").to(device)\n",
        "\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "def acc(pred, label):\n",
        "    pred_class = torch.argmax(pred, dim=1)\n",
        "    correct = torch.sum(pred_class == label).item()\n",
        "    return correct"
      ],
      "metadata": {
        "id": "xJUcAEN6E4Af"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 5\n",
        "epochs = 6\n",
        "\n",
        "valid_loss_min = np.inf\n",
        "\n",
        "epoch_tr_loss, epoch_vl_loss = [], []\n",
        "epoch_tr_acc,  epoch_vl_acc  = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # training\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    train_acc = 0  # count of correct predictions\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        h = model.init_hidden(batch_size=inputs.size(0), device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, h = model(inputs, h)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        train_acc += acc(logits, labels)\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            h = model.init_hidden(batch_size=inputs.size(0), device=device)\n",
        "\n",
        "            logits, h = model(inputs, h)\n",
        "            val_loss = criterion(logits, labels)\n",
        "            val_losses.append(val_loss.item())\n",
        "            val_acc += acc(logits, labels)\n",
        "\n",
        "    # ---- EPOCH METRICS ----\n",
        "    epoch_train_loss = float(np.mean(train_losses)) if train_losses else 0.0\n",
        "    epoch_val_loss   = float(np.mean(val_losses))   if val_losses   else 0.0\n",
        "    epoch_train_acc  = train_acc / len(train_loader.dataset)\n",
        "    epoch_val_acc    = val_acc   / len(val_loader.dataset)\n",
        "\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}\")\n",
        "    print(f\"train_loss: {epoch_train_loss}  val_loss: {epoch_val_loss}\")\n",
        "    print(f\"train_acc : {epoch_train_acc*100}%  val_acc : {epoch_val_acc*100}%\")\n",
        "    print(25*'==')\n",
        "\n",
        "    if epoch_val_loss < valid_loss_min:\n",
        "        valid_loss_min = epoch_val_loss\n",
        "        # torch.save(model.state_dict(), \"best.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7e5iDEUHXQc",
        "outputId": "842e4691-7fde-4413-e264-c22975a10df0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "train_loss: 0.6385302984288761  val_loss: 0.5925555273890495\n",
            "train_acc : 76.47142857142856%  val_acc : 80.80000000000001%\n",
            "==================================================\n",
            "Epoch 2\n",
            "train_loss: 0.45167421134454866  val_loss: 0.5900026157498359\n",
            "train_acc : 83.1%  val_acc : 78.10000000000001%\n",
            "==================================================\n",
            "Epoch 3\n",
            "train_loss: 0.3845385314098426  val_loss: 0.47913323864340784\n",
            "train_acc : 84.97142857142858%  val_acc : 84.0%\n",
            "==================================================\n",
            "Epoch 4\n",
            "train_loss: 0.34153792623962675  val_loss: 0.4556539759039879\n",
            "train_acc : 87.12857142857143%  val_acc : 83.5%\n",
            "==================================================\n",
            "Epoch 5\n",
            "train_loss: 0.29644670757864205  val_loss: 0.477424106746912\n",
            "train_acc : 88.52857142857142%  val_acc : 84.3%\n",
            "==================================================\n",
            "Epoch 6\n",
            "train_loss: 0.2603928263698305  val_loss: 0.49704570323228836\n",
            "train_acc : 90.17142857142856%  val_acc : 83.8%\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the evaluation\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "test_acc = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        h = model.init_hidden(batch_size=inputs.size(0), device=device)\n",
        "        logits, h = model(inputs, h)\n",
        "        loss = criterion(logits, labels)\n",
        "        test_loss += loss.item() * inputs.size(0)\n",
        "        test_acc += acc(logits, labels)\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "test_acc  /= len(test_loader.dataset)\n",
        "\n",
        "print(f\"Test Loss: {test_loss} | Test Accuracy: {test_acc*100}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhyNnYHKew7Y",
        "outputId": "4f9b6fa9-de22-45f7-90bc-79ee78b42f2d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.4506717845797539 | Test Accuracy: 83.05%\n"
          ]
        }
      ]
    }
  ]
}