{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09838c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_total': 10000, 'n_train': 7000, 'n_val': 1000, 'n_test': 2000, 'n_features': 42199, 'train_class_counts': Counter({'positive': 5174, 'negative': 1120, 'neutral': 706}), 'val_class_counts': Counter({'positive': 739, 'negative': 160, 'neutral': 101}), 'test_class_counts': Counter({'positive': 1478, 'negative': 320, 'neutral': 202}), 'files': {'dataset_with_split': 'C:\\\\Users\\\\User\\\\OneDrive\\\\Y3S1\\\\BT4222\\\\project\\\\sia_preproc_70_10_20\\\\sia_reviews_with_split.csv', 'X_train_tfidf': 'C:\\\\Users\\\\User\\\\OneDrive\\\\Y3S1\\\\BT4222\\\\project\\\\sia_preproc_70_10_20\\\\X_train_tfidf.npz', 'X_val_tfidf': 'C:\\\\Users\\\\User\\\\OneDrive\\\\Y3S1\\\\BT4222\\\\project\\\\sia_preproc_70_10_20\\\\X_val_tfidf.npz', 'X_test_tfidf': 'C:\\\\Users\\\\User\\\\OneDrive\\\\Y3S1\\\\BT4222\\\\project\\\\sia_preproc_70_10_20\\\\X_test_tfidf.npz', 'tfidf_vectorizer.pkl': 'C:\\\\Users\\\\User\\\\OneDrive\\\\Y3S1\\\\BT4222\\\\project\\\\sia_preproc_70_10_20\\\\tfidf_vectorizer.pkl', 'train_split.csv': 'C:\\\\Users\\\\User\\\\OneDrive\\\\Y3S1\\\\BT4222\\\\project\\\\sia_preproc_70_10_20\\\\train_split.csv', 'val_split.csv': 'C:\\\\Users\\\\User\\\\OneDrive\\\\Y3S1\\\\BT4222\\\\project\\\\sia_preproc_70_10_20\\\\val_split.csv', 'test_split.csv': 'C:\\\\Users\\\\User\\\\OneDrive\\\\Y3S1\\\\BT4222\\\\project\\\\sia_preproc_70_10_20\\\\test_split.csv'}}\n"
     ]
    }
   ],
   "source": [
    "# Preprocess SIA reviews with 70/10/20 split (train/val/test), combine title+text, clean, stopwords, TF-IDF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import save_npz\n",
    "import pickle\n",
    "\n",
    "# ---------- Load data ----------\n",
    "in_path = Path(r\"C:\\Users\\User\\OneDrive\\Y3S1\\BT4222\\project\\singapore_airlines_reviews.csv\")\n",
    "df = pd.read_csv(in_path)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# ---------- Combine title + text ----------\n",
    "df[\"combined_review\"] = (df[\"title\"].fillna(\"\") + \" \" + df[\"text\"].fillna(\"\")).str.strip()\n",
    "\n",
    "# ---------- Proxy sentiment from rating ----------\n",
    "def map_rating_to_sentiment(x):\n",
    "    try:\n",
    "        r = float(x)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "    if r <= 2:  return \"negative\"\n",
    "    if r >= 4:  return \"positive\"\n",
    "    return \"neutral\"\n",
    "\n",
    "df[\"sentiment_proxy\"] = df[\"rating\"].apply(map_rating_to_sentiment)\n",
    "\n",
    "# ---------- Cleaner ----------\n",
    "emoji_pattern = re.compile(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)')\n",
    "tag_pattern   = re.compile(r'<[^>]*>')\n",
    "nonword_pat   = re.compile(r'[\\W]+')\n",
    "\n",
    "def preprocessor(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\" if pd.isna(text) else str(text)\n",
    "    text = tag_pattern.sub('', text)\n",
    "    emojis = emoji_pattern.findall(text)\n",
    "    text = nonword_pat.sub(' ', text.lower()).strip()\n",
    "    if emojis:\n",
    "        text = text + ' ' + ' '.join(e.replace('-', '') for e in emojis)\n",
    "    return text\n",
    "\n",
    "# ---------- 70/10/20 split using row indices ----------\n",
    "idx_all = np.arange(len(df))\n",
    "y = df[\"sentiment_proxy\"].values\n",
    "strat_all = y if pd.Series(y).notna().all() else None\n",
    "\n",
    "# 80% train+val vs 20% test\n",
    "idx_trval, idx_test, y_trval, y_test = train_test_split(\n",
    "    idx_all, y,\n",
    "    test_size=0.20, random_state=42, stratify=strat_all\n",
    ")\n",
    "\n",
    "# from 80% (train+val), carve 10% total for val -> 12.5% of trval\n",
    "val_frac = 0.10 / 0.80\n",
    "strat_trval = y_trval if pd.Series(y_trval).notna().all() else None\n",
    "\n",
    "idx_train, idx_val, y_train, y_val = train_test_split(\n",
    "    idx_trval, y_trval,\n",
    "    test_size=val_frac, random_state=42, stratify=strat_trval\n",
    ")\n",
    "\n",
    "# ---------- Assign split labels back to df ----------\n",
    "df[\"split\"] = \"train\"\n",
    "df.loc[idx_val, \"split\"] = \"val\"\n",
    "df.loc[idx_test, \"split\"] = \"test\"\n",
    "\n",
    "# (Optional) Save the dataset with split labels for downstream use\n",
    "out_dir = Path(r\"C:\\Users\\User\\OneDrive\\Y3S1\\BT4222\\project\\sia_preproc_70_10_20\")\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "df.to_csv(out_dir / \"sia_reviews_with_split.csv\", index=False)\n",
    "\n",
    "# ---------- TF-IDF (fit on train only) ----------\n",
    "X_train_text = df.loc[idx_train, \"combined_review\"].astype(str).values\n",
    "X_val_text   = df.loc[idx_val,   \"combined_review\"].astype(str).values\n",
    "X_test_text  = df.loc[idx_test,  \"combined_review\"].astype(str).values\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    preprocessor=preprocessor,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "X_val_tfidf   = vectorizer.transform(X_val_text)\n",
    "X_test_tfidf  = vectorizer.transform(X_test_text)\n",
    "\n",
    "# ---------- Save artefacts ----------\n",
    "from scipy.sparse import save_npz\n",
    "save_npz(out_dir / \"X_train_tfidf.npz\", X_train_tfidf)\n",
    "save_npz(out_dir / \"X_val_tfidf.npz\", X_val_tfidf)\n",
    "save_npz(out_dir / \"X_test_tfidf.npz\", X_test_tfidf)\n",
    "\n",
    "with open(out_dir / \"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "pd.DataFrame({\"index\": idx_train, \"text\": X_train_text, \"label\": y_train}).to_csv(out_dir / \"train_split.csv\", index=False)\n",
    "pd.DataFrame({\"index\": idx_val,   \"text\": X_val_text,   \"label\": y_val}).to_csv(out_dir / \"val_split.csv\", index=False)\n",
    "pd.DataFrame({\"index\": idx_test,  \"text\": X_test_text,  \"label\": y_test}).to_csv(out_dir / \"test_split.csv\", index=False)\n",
    "\n",
    "summary = {\n",
    "    \"n_total\": int(len(df)),\n",
    "    \"n_train\": int(len(idx_train)),\n",
    "    \"n_val\":   int(len(idx_val)),\n",
    "    \"n_test\":  int(len(idx_test)),\n",
    "    \"n_features\": int(X_train_tfidf.shape[1]),\n",
    "    \"train_class_counts\": Counter(y_train),\n",
    "    \"val_class_counts\":   Counter(y_val),\n",
    "    \"test_class_counts\":  Counter(y_test),\n",
    "    \"files\": {\n",
    "        \"dataset_with_split\": str(out_dir / \"sia_reviews_with_split.csv\"),\n",
    "        \"X_train_tfidf\": str(out_dir / \"X_train_tfidf.npz\"),\n",
    "        \"X_val_tfidf\":   str(out_dir / \"X_val_tfidf.npz\"),\n",
    "        \"X_test_tfidf\":  str(out_dir / \"X_test_tfidf.npz\"),\n",
    "        \"tfidf_vectorizer.pkl\": str(out_dir / \"tfidf_vectorizer.pkl\"),\n",
    "        \"train_split.csv\": str(out_dir / \"train_split.csv\"),\n",
    "        \"val_split.csv\":   str(out_dir / \"val_split.csv\"),\n",
    "        \"test_split.csv\":  str(out_dir / \"test_split.csv\"),\n",
    "    }\n",
    "}\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
