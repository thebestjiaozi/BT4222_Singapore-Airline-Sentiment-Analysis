{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h3y3vnI0i584"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import csv\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import save_npz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSjyXLgUjFOG",
        "outputId": "b40d3fec-10e1-4d65-a200-798108592409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#PROCESS SKYTRAX REVIEWS\n",
        "df1 = pd.read_csv(\"data/skytrax_reviews.csv\")\n",
        "df2 = pd.read_csv(\"data/skytrax_reviews2.csv\")\n",
        "df3 = pd.read_csv(\"data/skytrax_reviews3.csv\")\n",
        "df4 = pd.read_csv(\"data/skytrax_reviews4.csv\")\n",
        "df_skytrax = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
        "\n",
        "df_skytrax[\"text\"] = df_skytrax[\"body\"].apply(lambda x: re.sub(r\"^.*\\|\\s*\", \"\", str(x)).strip())\n",
        "df_skytrax[\"title\"] = df_skytrax[\"title\"].apply(lambda x: re.sub(r'[\"“”]', '', str(x)).strip())\n",
        "df_skytrax[\"combined_review\"] = df_skytrax[\"text\"]\n",
        "\n",
        "#Normalize rating and create sentiment proxy\n",
        "df_skytrax[\"rating_normalized\"] = (df_skytrax[\"rating_value_10\"] / 2).round().astype(int).clip(1, 5)\n",
        "\n",
        "def label_sentiment(r):\n",
        "    if r <= 2: return \"negative\"\n",
        "    elif r == 3: return \"neutral\"\n",
        "    else: return \"positive\"\n",
        "\n",
        "df_skytrax[\"sentiment_proxy\"] = df_skytrax[\"rating_normalized\"].apply(label_sentiment)\n",
        "\n",
        "#Clean up quotation marks\n",
        "df_skytrax[\"combined_review\"] = (\n",
        "    df_skytrax[\"combined_review\"]\n",
        "    .astype(str)\n",
        "    .str.strip()\n",
        "    .str.replace(r'^\"+|\"+$', '', regex=True)\n",
        ")\n",
        "\n",
        "#Drop NaNs and duplicates\n",
        "df_skytrax.dropna(subset=[\"combined_review\", \"sentiment_proxy\"], inplace=True)\n",
        "df_skytrax.drop_duplicates(subset=[\"combined_review\"], inplace=True)\n",
        "\n",
        "df_skytrax_final = df_skytrax[[\"combined_review\", \"sentiment_proxy\"]].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7sbU-n-rby6"
      },
      "outputs": [],
      "source": [
        "#process SIA reviews from kaggle\n",
        "df_sia = pd.read_csv(\"data/singapore_airlines_reviews.csv\")\n",
        "df_sia.columns = [c.strip() for c in df_sia.columns]\n",
        "df_sia[\"combined_review\"] = (df_sia[\"title\"].fillna(\"\") + \" \" + df_sia[\"text\"].fillna(\"\")).str.strip()\n",
        "def map_rating_to_sentiment(x):\n",
        "  try:\n",
        "    r = float(x)\n",
        "  except Exception:\n",
        "    return np.nan\n",
        "  if r <= 2: return \"negative\"\n",
        "  if r >= 4: return \"positive\"\n",
        "  return \"neutral\"\n",
        "\n",
        "df_sia[\"sentiment_proxy\"] = df_sia[\"rating\"].apply(map_rating_to_sentiment)\n",
        "#Drop NaNs and duplicates\n",
        "df_sia.dropna(subset=[\"combined_review\", \"sentiment_proxy\"], inplace=True)\n",
        "df_sia.drop_duplicates(subset=[\"combined_review\"], inplace=True)\n",
        "\n",
        "df_sia_final = df_sia[[\"combined_review\", \"sentiment_proxy\"]].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDI4q9-_uyEj",
        "outputId": "c0444cb9-6ba9-413b-d3a8-03db643d8602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All data combined and cleaned. Final DataFrame shape: (11665, 2)\n",
            "sentiment_proxy\n",
            "positive    8462\n",
            "negative    2095\n",
            "neutral     1108\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Concatenate Dataframes\n",
        "df = pd.concat([df_skytrax_final, df_sia_final], ignore_index=True)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(subset=[\"combined_review\"], inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(f\"All data combined and cleaned. Final DataFrame shape: {df.shape}\")\n",
        "print(df[\"sentiment_proxy\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48LKaUFuvA1W",
        "outputId": "43aa9bc1-7ce9-4b28-a83d-0c7cd1c0b440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data successfully split into 70% train, 10% val, 20% test.\n",
            "TF-IDF vectorization complete. Vocabulary size: 51228\n"
          ]
        }
      ],
      "source": [
        "#DATA SPLIT & PREPROCESSING\n",
        "emoji_pattern = re.compile(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)')\n",
        "tag_pattern   = re.compile(r'<[^>]*>')\n",
        "nonword_pat   = re.compile(r'[\\W]+')\n",
        "\n",
        "def preprocessor(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        text = \"\" if pd.isna(text) else str(text)\n",
        "    text = tag_pattern.sub('', text)\n",
        "    emojis = emoji_pattern.findall(text)\n",
        "    text = nonword_pat.sub(' ', text.lower()).strip()\n",
        "    if emojis:\n",
        "        text = text + ' ' + ' '.join(e.replace('-', '') for e in emojis)\n",
        "    return text\n",
        "\n",
        "# 70/10/20 split\n",
        "idx_all = np.arange(len(df))\n",
        "y = df[\"sentiment_proxy\"].values\n",
        "# Check for NaNs in y before stratifying (though we already dropped them)\n",
        "strat_all = y if pd.Series(y).notna().all() else None\n",
        "\n",
        "if strat_all is None:\n",
        "    print(\"Warning: NaNs found in target variable 'y'. Proceeding without stratification.\")\n",
        "\n",
        "# 80% train+val vs 20% test\n",
        "idx_trval, idx_test, y_trval, y_test = train_test_split(\n",
        "    idx_all, y,\n",
        "    test_size=0.20, random_state=42, stratify=strat_all\n",
        ")\n",
        "\n",
        "# 10% val vs 70% train (from the 80% trval)\n",
        "val_frac = 0.10 / 0.80  # 0.125\n",
        "strat_trval = y_trval if pd.Series(y_trval).notna().all() else None\n",
        "\n",
        "idx_train, idx_val, y_train, y_val = train_test_split(\n",
        "    idx_trval, y_trval,\n",
        "    test_size=val_frac, random_state=42, stratify=strat_trval\n",
        ")\n",
        "\n",
        "# Add split column back to the dataframe for reference\n",
        "df[\"split\"] = \"train\"\n",
        "df.loc[idx_val, \"split\"] = \"val\"\n",
        "df.loc[idx_test, \"split\"] = \"test\"\n",
        "\n",
        "print(\"Data successfully split into 70% train, 10% val, 20% test.\")\n",
        "\n",
        "# Get text data for vectorization\n",
        "X_train_text = df.loc[idx_train, \"combined_review\"].astype(str).values\n",
        "X_val_text   = df.loc[idx_val, \"combined_review\"].astype(str).values\n",
        "X_test_text  = df.loc[idx_test, \"combined_review\"].astype(str).values\n",
        "\n",
        "# Initialize and fit TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(\n",
        "    preprocessor=preprocessor,\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=2,\n",
        "    max_df=0.95\n",
        ")\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
        "X_val_tfidf   = vectorizer.transform(X_val_text)\n",
        "X_test_tfidf  = vectorizer.transform(X_test_text)\n",
        "\n",
        "print(f\"TF-IDF vectorization complete. Vocabulary size: {X_train_tfidf.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Save\n",
        "out_dir = Path(\"data/combined_split\")\n",
        "out_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Save the dataset with split labels\n",
        "df.to_csv(out_dir / \"combined_reviews_with_split.csv\", index=False)\n",
        "\n",
        "# Save split dataframes\n",
        "pd.DataFrame({\"index\": idx_train, \"text\": X_train_text, \"label\": y_train}).to_csv(out_dir / \"train_split.csv\", index=False)\n",
        "pd.DataFrame({\"index\": idx_val, \"text\": X_val_text,   \"label\": y_val}).to_csv(out_dir / \"val_split.csv\", index=False)\n",
        "pd.DataFrame({\"index\": idx_test, \"text\": X_test_text,  \"label\": y_test}).to_csv(out_dir / \"test_split.csv\", index=False)\n",
        "\n",
        "# Save TF-IDF matrices and vectorizer\n",
        "save_npz(out_dir / \"X_train_tfidf.npz\", X_train_tfidf)\n",
        "save_npz(out_dir / \"X_val_tfidf.npz\", X_val_tfidf)\n",
        "save_npz(out_dir / \"X_test_tfidf.npz\", X_test_tfidf)\n",
        "\n",
        "with open(out_dir / \"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vectorizer, f)\n",
        "\n",
        "print(f\"All artifacts saved to '{out_dir}' directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBIg6N3CvP5P",
        "outputId": "b6f3e1c5-f6b0-43fa-d49f-957e611800fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_total': 11665, 'n_train': 8165, 'n_val': 1167, 'n_test': 2333, 'n_features': 51228, 'train_class_counts': Counter({'positive': 5923, 'negative': 1467, 'neutral': 775}), 'val_class_counts': Counter({'positive': 847, 'negative': 209, 'neutral': 111}), 'test_class_counts': Counter({'positive': 1692, 'negative': 419, 'neutral': 222})}\n"
          ]
        }
      ],
      "source": [
        "#Summary\n",
        "summary = {\n",
        "    \"n_total\": int(len(df)),\n",
        "    \"n_train\": int(len(idx_train)),\n",
        "    \"n_val\":   int(len(idx_val)),\n",
        "    \"n_test\":  int(len(idx_test)),\n",
        "    \"n_features\": int(X_train_tfidf.shape[1]),\n",
        "    \"train_class_counts\": Counter(y_train),\n",
        "    \"val_class_counts\":   Counter(y_val),\n",
        "    \"test_class_counts\":  Counter(y_test)\n",
        "}\n",
        "print(summary)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
