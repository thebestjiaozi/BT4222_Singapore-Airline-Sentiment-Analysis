{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wX1XLdMxn8sm"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, f1_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCLpu_PqoGFX",
        "outputId": "2e8582c9-250a-47f4-d8c9-8f1851815f00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU not available, CPU used\n"
          ]
        }
      ],
      "source": [
        "# Check cuda status\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P04WpsMoGzL",
        "outputId": "8ecc6e40-3d8d-4da2-d763-fbdbc5a46e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_df = pd.read_csv(\"../data/combined_split/train_split.csv\")\n",
        "val_df = pd.read_csv(\"../data/combined_split/val_split.csv\")\n",
        "test_df = pd.read_csv(\"../data/combined_split/test_split.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlOh8NjZ4b_R",
        "outputId": "8eaebe35-6c15-4be9-d13d-545e048a4626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of train data is (8165, 3)\n",
            "shape of test data is (1167, 3)\n",
            "shape of test data is (2333, 3)\n"
          ]
        }
      ],
      "source": [
        "print(f'shape of train data is {train_df.shape}')\n",
        "print(f'shape of test data is {val_df.shape}')\n",
        "print(f'shape of test data is {test_df.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYlFntyr4pha",
        "outputId": "aaa6ad69-1bef-4f22-e20b-3d2b178705b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "# Tokenization\n",
        "def preprocess_string(s):\n",
        "    # Remove all non-word characters (everything except numbers and letters)\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    # Replace all runs of whitespaces with no space\n",
        "    s = re.sub(r\"\\s+\", '', s)\n",
        "    # replace digits with no space\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "\n",
        "    return s.strip().lower()\n",
        "\n",
        "def tokenize_text(train_df, val_df, test_df, vocab_size=1000):\n",
        "    word_list = []\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    for text in train_df['text']:\n",
        "        for word in text.split():\n",
        "            word = preprocess_string(word)\n",
        "            if word and word not in stop_words:\n",
        "                word_list.append(word)\n",
        "\n",
        "    corpus = Counter(word_list)\n",
        "    top_words = sorted(corpus, key=corpus.get, reverse=True)[:vocab_size]\n",
        "    onehot_dict = {w: i+1 for i, w in enumerate(top_words)}\n",
        "\n",
        "    def tokenize_column(df):\n",
        "        tokenized = []\n",
        "        for text in df['text']:\n",
        "            tokens = [onehot_dict[preprocess_string(word)]\n",
        "                      for word in text.split()\n",
        "                      if preprocess_string(word) in onehot_dict]\n",
        "            tokenized.append(tokens)\n",
        "        return np.array(tokenized, dtype=object)\n",
        "\n",
        "\n",
        "    x_train_tokens = tokenize_column(train_df)\n",
        "    x_val_tokens   = tokenize_column(val_df)\n",
        "    x_test_tokens  = tokenize_column(test_df)\n",
        "\n",
        "    y_train = train_df['label'].values\n",
        "    y_val   = val_df['label'].values\n",
        "    y_test  = test_df['label'].values\n",
        "\n",
        "    return x_train_tokens, y_train, x_val_tokens, y_val, x_test_tokens, y_test, onehot_dict\n",
        "\n",
        "x_train, y_train, x_val, y_val, x_test, y_test, vocab = tokenize_text(train_df, val_df, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCuN_arzBTmZ",
        "outputId": "0cc5483e-72fe-4531-e075-d0ea241e9ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of vocabulary is 1000\n"
          ]
        }
      ],
      "source": [
        "print(f'Length of vocabulary is {len(vocab)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "YAKjJceZB5Dh",
        "outputId": "abc96a53-b46c-4db5-a476-9050dfe091d1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8165.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>43.508757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>39.088507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>21.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>33.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>52.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ],
            "text/plain": [
              "count    8165.000000\n",
              "mean       43.508757\n",
              "std        39.088507\n",
              "min         4.000000\n",
              "25%        21.000000\n",
              "50%        33.000000\n",
              "75%        52.000000\n",
              "max      1100.000000\n",
              "dtype: float64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rev_len = [len(i) for i in x_train]\n",
        "pd.Series(rev_len).hist()\n",
        "plt.show()\n",
        "pd.Series(rev_len).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICGkPbmWCovG"
      },
      "source": [
        "count = 8165 -> There are 8165 training samples. <br>\n",
        "mean = 43.51 -> On average, each review has around 44 tokens. <br>\n",
        "std = 39.1 -> There’s large standard deviation. Some reviews are very short while some are very long. <br>\n",
        "min = 4\t-> The shortest review has only 4 tokens. <br>\n",
        "25% = 21 -> 25% of reviews have ≤ 21 tokens. <br>\n",
        "50% = 33 -> Half of the reviews have ≤ 33 tokens. <br>\n",
        "75% = 52 -> 75% of reviews have ≤ 52 tokens. <br>\n",
        "max = 1100 -> The longest review is 1100 tokens long"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Q2eLoFDSv7",
        "outputId": "1775c9d2-3afd-49d2-c065-53effeb801ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Text input: [127, 109, 7, 26, 917, 157, 263, 762, 750, 392, 127, 905, 750, 127, 50, 50, 170, 608, 58, 613, 97, 224, 776, 192]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('\\n Text input: {}\\n'.format(x_train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1KuHUEGD-RW",
        "outputId": "0fdf681b-8f15-4b25-9502-65d19b7e3529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90th percentile length: 83\n",
            "95th percentile length: 109\n",
            "99th percentile length: 187\n"
          ]
        }
      ],
      "source": [
        "for p in [90, 95, 99]:\n",
        "    print(f\"{p}th percentile length: {np.percentile(rev_len, p):.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpL_UhkIDo9y"
      },
      "outputs": [],
      "source": [
        "def padding_(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "    return features\n",
        "\n",
        "#we have very less number of reviews with length > 120 as the 95th percentile length is 106.\n",
        "#So we will consider only those below it.\n",
        "x_train_pad = padding_(x_train, 120)\n",
        "x_val_pad   = padding_(x_val, 120)\n",
        "x_test_pad  = padding_(x_test, 120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD_y43Eb86yI",
        "outputId": "ea5f17c3-64c9-4fd2-9a66-20ca7d385e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['negative' 'neutral' 'positive']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_val   = le.transform(y_val)\n",
        "y_test  = le.transform(y_test)\n",
        "\n",
        "print(le.classes_)  #should print ['negative' 'neutral' 'positive']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N318VTz478G7"
      },
      "outputs": [],
      "source": [
        "train_data = TensorDataset(\n",
        "    torch.from_numpy(x_train_pad),\n",
        "    torch.from_numpy(y_train)\n",
        ")\n",
        "\n",
        "val_data = TensorDataset(\n",
        "    torch.from_numpy(x_val_pad),\n",
        "    torch.from_numpy(y_val)\n",
        ")\n",
        "\n",
        "test_data = TensorDataset(\n",
        "    torch.from_numpy(x_test_pad),\n",
        "    torch.from_numpy(y_test)\n",
        ")\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "val_loader   = DataLoader(val_data,   shuffle=True, batch_size=batch_size)\n",
        "test_loader  = DataLoader(test_data,  shuffle=False, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnaWPXSJ-GCB",
        "outputId": "4d8eb550-df1e-440c-e0d5-34c17b483f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 120])\n",
            "Sample sentences x: \n",
            " tensor([[  0,   0,   0,  ...,   4, 111,  13],\n",
            "        [  0,   0,   0,  ..., 345, 489, 155],\n",
            "        [  0,   0,   0,  ..., 132, 542, 102],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  52,  40,   5],\n",
            "        [997,   2,  36,  ...,   8,   9,   3],\n",
            "        [  0,   0,   0,  ...,  22,  48, 368]])\n",
            "Sample targets y: \n",
            " tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 1, 0, 2, 2,\n",
            "        2, 2])\n"
          ]
        }
      ],
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample sentences x: \\n', sample_x)\n",
        "print('Sample targets y: \\n', sample_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6sG1jpj_CRR"
      },
      "outputs": [],
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        embedding_dim=128,\n",
        "        hidden_dim=128,\n",
        "        num_layers=2,\n",
        "        num_classes=3,         #3 classes from le()\n",
        "        bidirectional=True,\n",
        "        dropout=0.3,\n",
        "        pad_idx=0               #padding index is 0\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * self.num_directions, num_classes)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        emb = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(emb, hidden)\n",
        "        last_hidden = lstm_out[:, -1, :]\n",
        "        out = self.dropout(last_hidden)\n",
        "        logits = self.fc(out)          # [B, 3]\n",
        "        return logits, hidden          # CE expects raw logits + int targets\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size, device):\n",
        "        h0 = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_dim, device=device)\n",
        "        c0 = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_dim, device=device)\n",
        "        return (h0, c0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJUcAEN6E4Af"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab) + 1      # +1 for PAD=0\n",
        "model = SentimentRNN(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=96,\n",
        "    hidden_dim=96,\n",
        "    num_layers=2,\n",
        "    num_classes=3,\n",
        "    bidirectional=True,\n",
        "    dropout=0.3,\n",
        "    pad_idx=0\n",
        ").to(device)\n",
        "\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "def acc(pred, label):\n",
        "    pred_class = torch.argmax(pred, dim=1)\n",
        "    correct = torch.sum(pred_class == label).item()\n",
        "    return correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7e5iDEUHXQc",
        "outputId": "5b0414ac-a307-49b8-c042-2ea3ae964800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "train_loss: 0.6382562329129475  val_loss: 0.5151971442004045\n",
            "train_acc : 76.39926515615431%  val_acc : 79.34875749785776%\n",
            "==================================================\n",
            "Epoch 2\n",
            "train_loss: 0.4508618046416015  val_loss: 0.47368205276628333\n",
            "train_acc : 82.90263319044703%  val_acc : 82.09083119108827%\n",
            "==================================================\n",
            "Epoch 3\n",
            "train_loss: 0.38387327950175215  val_loss: 0.42706238354245823\n",
            "train_acc : 85.3153704837722%  val_acc : 83.54755784061697%\n",
            "==================================================\n",
            "Epoch 4\n",
            "train_loss: 0.34092626202760673  val_loss: 0.465048935264349\n",
            "train_acc : 86.62584200857317%  val_acc : 83.29048843187661%\n",
            "==================================================\n",
            "Epoch 5\n",
            "train_loss: 0.3031915070988783  val_loss: 0.5155874391396841\n",
            "train_acc : 88.30373545621556%  val_acc : 82.60497000856898%\n",
            "==================================================\n",
            "Epoch 6\n",
            "train_loss: 0.2573274951428175  val_loss: 0.4830886423587799\n",
            "train_acc : 90.18983466013472%  val_acc : 83.29048843187661%\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "clip = 5\n",
        "epochs = 6\n",
        "\n",
        "valid_loss_min = np.inf\n",
        "\n",
        "epoch_tr_loss, epoch_vl_loss = [], []\n",
        "epoch_tr_acc,  epoch_vl_acc  = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # training\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    train_acc = 0  # count of correct predictions\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        h = model.init_hidden(batch_size=inputs.size(0), device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, h = model(inputs, h)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        train_acc += acc(logits, labels)\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            h = model.init_hidden(batch_size=inputs.size(0), device=device)\n",
        "\n",
        "            logits, h = model(inputs, h)\n",
        "            val_loss = criterion(logits, labels)\n",
        "            val_losses.append(val_loss.item())\n",
        "            val_acc += acc(logits, labels)\n",
        "\n",
        "    # ---- EPOCH METRICS ----\n",
        "    epoch_train_loss = float(np.mean(train_losses)) if train_losses else 0.0\n",
        "    epoch_val_loss   = float(np.mean(val_losses))   if val_losses   else 0.0\n",
        "    epoch_train_acc  = train_acc / len(train_loader.dataset)\n",
        "    epoch_val_acc    = val_acc   / len(val_loader.dataset)\n",
        "\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}\")\n",
        "    print(f\"train_loss: {epoch_train_loss}  val_loss: {epoch_val_loss}\")\n",
        "    print(f\"train_acc : {epoch_train_acc*100}%  val_acc : {epoch_val_acc*100}%\")\n",
        "    print(25*'==')\n",
        "\n",
        "    if epoch_val_loss < valid_loss_min:\n",
        "        valid_loss_min = epoch_val_loss\n",
        "        # torch.save(model.state_dict(), \"best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhyNnYHKew7Y",
        "outputId": "7c2cceba-f149-46d7-862c-dccc9f6c2cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 83.29%  Validation Macro-F1: 0.6404  Test Accuracy: 82.77%  Test Macro-F1: 0.6414\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def evaluate_split(model, loader, device):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            h = model.init_hidden(batch_size=inputs.size(0), device=device)\n",
        "            logits, h = model(inputs, h)\n",
        "            preds = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
        "\n",
        "            total_correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = total_correct / total\n",
        "    f1m = f1_score(all_labels, all_preds, average='macro')\n",
        "    return acc, f1m\n",
        "\n",
        "\n",
        "val_acc, val_f1 = evaluate_split(model, val_loader, device)\n",
        "test_acc, test_f1 = evaluate_split(model, test_loader, device)\n",
        "\n",
        "print(\n",
        "    f\"Validation Accuracy: {val_acc*100:.2f}%  \"\n",
        "    f\"Validation Macro-F1: {val_f1:.4f}  \"\n",
        "    f\"Test Accuracy: {test_acc*100:.2f}%  \"\n",
        "    f\"Test Macro-F1: {test_f1:.4f}\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
